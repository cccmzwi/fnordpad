#!/bin/bash

# Kein Kommentar #

## Variablen
# Zielordner der Bilder
ordner=$HOME/bilder
# Namen der soups
suppe=(fnordpad gnd cccmz sixtus fotochaoten kochchaoten)
# Twitter wird geparst um Bilder von Instagram zu finden
zwitscher=(cccmz cccmzwi spookey lambda_ kventil lsanoj)

soupfeed() {
	# Adresse zusammenstückeln
	url=http://${name}.soup.io/rss/
	wget -qO - $url | grep -o '<enclosure [^>]*>' | grep -o 'http://[^\"]*'  | sed 's/_[0-9][0-9][0-9]\././' | sed 's/\.jpeg/.jpg/'
}

soupweb() {
	# Wie viele Seiten soll ich gehen?
	if [ -z $2 ]; then
		pages=5
	else
		pages=$2
	fi

	for ((i=0; i<pages; i++)); do
		# Adresse zusammenstückeln
		url=http://${name}.soup.io/${since}
		wget -qO - $url | grep -o 'http://[0-9a-z].asset.soup.io/asset/[^0000][^\"]*' | grep -wv square* | sed 's/_[0-9][0-9][0-9]\././' | sed 's/_[0-9][0-9]\././' | sed 's/\.jpeg/.jpg/'
		# Umblättern
		since=$(wget -qO - $url | grep -w 'SOUP.Endless.next_url' | grep -o 'since[^?;]*' )
	done
}

twinsta() {
	url=https://api.twitter.com/1/statuses/user_timeline.rss?screen_name=$name
	twstr=$(wget -qO - $url | grep -w 'guid*' | grep -o 'http[^\<]*')
	for line in $twstr; do
		insta=$(wget -qO - $line | grep -o 'http://instagr[^\"\ ]*' )

		if [ -n "$insta" ]; then
			wget -qO - $insta | grep -w 'img class="photo"' | grep -o 'http://[^\"]*'
		else
			echo "https://raw.github.com/spookey/fnordpad/master/fnordpad.jpg"
		fi
		# this is awesome code!!1!
		
	done
}

# Bilderordner anlegen, falls er nicht existiert
if [ ! -d "$ordner" ]; then
  mkdir -p $ordner
fi

for name in ${zwitscher[@]}; do

	# Bilder von Instagram via Twitter
	wget -qc -P $ordner $(twinsta $name)

done

for name in ${suppe[@]}; do

	# die rss Feeds parsen
	wget -qc -P $ordner $(soupfeed $name)

	# die Reposts von der Seite holen
	wget -qc -P $ordner $(soupweb $name)

done

exit 0
